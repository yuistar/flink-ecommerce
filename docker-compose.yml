---
version: '3.8'
x-kafka-common:
  &kafka-common
  image: confluentinc/cp-kafka:7.9.0
  networks:
    kafka-flink-net:
  environment:
    &kafka-common-env
    KAFKA_PROCESS_ROLES: 'broker,controller'
    KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kakfa-1:29093,2@kafka-2:29093,3@kafka-3:29093' # kraft
    KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
    KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'

    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
    KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

    KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
    KAFKA_JMX_PORT: 9101
    KAFKA_JMX_HOSTNAME: localhost
    KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#    KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
    CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka-1:29092
    CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1

    KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
    KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
    CONFLUENT_METRICS_ENABLE: 'true'
    CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
    # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
    CLUSTER_ID: 'm1Ze6AjGRwqarkcxJscgyQ'


services:
  postgres:
    image: postgres:latest
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.5
    container_name: es-container
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
    ports:
      - 9200:9200

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.5
    container_name: kb-container
    environment:
      - ELASTICSEARCH_HOSTS=http://es-container:9200
      - XPACK_SECURITY_ENABLED=false
    depends_on:
      - elasticsearch
    ports:
      - 5601:5601

#  zookeeper:
#    image: confluentinc/cp-zookeeper:7.9.0
#    hostname: zookeeper
#    container_name: zookeeper
#    ports:
#      - "2181:2181"
#    environment:
#      ZOOKEEPER_CLIENT_PORT: 2181
#      ZOOKEEPER_TICKET_TIME: 2000
#    healthcheck:
#      test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
#      interval: 10s
#      timeout: 5s
#      retries: 5

  kafka-1:
    <<: *kafka-common
    container_name: kafka-1
#    depends_on:
#      zookeeper:
#        condition: service_healthy
    ports:
      - "9091:9091"
    environment:
      <<: *kafka-common-env
      KAFKA_NODE_ID: 1
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9091'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka-1:29092,CONTROLLER://kafka-1:29093,PLAINTEXT_HOST://0.0.0.0:9091'

#    healthcheck: # zookeeper mode
#      test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
#      interval: 10s
#      timeout: 5s
#      retries: 5

  kafka-2:
    <<: *kafka-common
    container_name: kafka-2
    ports:
      - "9092:9092"
    environment:
      <<: *kafka-common-env
      KAFKA_NODE_ID: 2
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-2:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka-2:29092,CONTROLLER://kafka-2:29093,PLAINTEXT_HOST://0.0.0.0:9092'

  kafka-3:
    <<: *kafka-common
    container_name: kafka-3
    ports:
      - "9093:9093"
    environment:
      <<: *kafka-common-env
      KAFKA_NODE_ID: 3
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka-3:29092,PLAINTEXT_HOST://localhost:9093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka-3:29092,CONTROLLER://kafka-3:29093,PLAINTEXT_HOST://0.0.0.0:9093'

  schema-registry:
    image: confluentinc/cp-schema-registry:7.9.0
    hostname: schema-registry
    container_name: schema-registry
    networks:
      kafka-flink-net:
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "18081:18081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_DEBUG: "true"
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka-1:29092,kafka-2:29092,kafka-3:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:18081
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: "full_transitive"

  schema-registry-ui:
    image: landoop/schema-registry-ui
    hostname: schema-registry
    restart: always
    container_name: schema-registry-ui
    networks:
      kafka-flink-net:
    depends_on:
      - schema-registry
    ports:
      - "7999:8000"
    environment:
      SCHEMAREGISTRY_URL: http://schema-registry:18081
      PROXY: "true"
      ALLOW_GLOBAL: "true"
      ALLOW_TRANSITIVE: "true"
      ALLOW_DELETION: "true"

#  connect:
#    image: cnfldemos/cp-server-connect-datagen:0.6.4-7.6.0
#    hostname: connect
#    container_name: connect
#    depends_on:
#      - broker
#      - schema-registry
#    ports:
#      - "8083:8083"
#    environment:
#      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
#      CONNECT_REST_ADVERTISED_HOST_NAME: connect
#      CONNECT_GROUP_ID: compose-connect-group
#      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
#      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
#      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
#      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
#      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#      # CLASSPATH required due to CC-2422
#      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-7.9.0.jar
#      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
#      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
#      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

#
#  ksqldb-server:
#    image: confluentinc/cp-ksqldb-server:7.9.0
#    hostname: ksqldb-server
#    container_name: ksqldb-server
#    depends_on:
#      - broker
#      - connect
#    ports:
#      - "8088:8088"
#    environment:
#      KSQL_CONFIG_DIR: "/etc/ksql"
#      KSQL_BOOTSTRAP_SERVERS: "broker:29092"
#      KSQL_HOST_NAME: ksqldb-server
#      KSQL_LISTENERS: "http://0.0.0.0:8088"
#      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
#      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
#      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
#      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
#      KSQL_KSQL_CONNECT_URL: "http://connect:8083"
#      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
#      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
#      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
#
#  ksqldb-cli:
#    image: confluentinc/cp-ksqldb-cli:7.9.0
#    container_name: ksqldb-cli
#    depends_on:
#      - broker
#      - connect
#      - ksqldb-server
#    entrypoint: /bin/sh
#    tty: true
#
#  ksql-datagen:
#    image: confluentinc/ksqldb-examples:7.9.0
#    hostname: ksql-datagen
#    container_name: ksql-datagen
#    depends_on:
#      - ksqldb-server
#      - broker
#      - schema-registry
#      - connect
#    command: "bash -c 'echo Waiting for Kafka to be ready... && \
#                       cub kafka-ready -b broker:29092 1 40 && \
#                       echo Waiting for Confluent Schema Registry to be ready... && \
#                       cub sr-ready schema-registry 8081 40 && \
#                       echo Waiting a few seconds for topic creation to finish... && \
#                       sleep 11 && \
#                       tail -f /dev/null'"
#    environment:
#      KSQL_CONFIG_DIR: "/etc/ksql"
#      STREAMS_BOOTSTRAP_SERVERS: broker:29092
#      STREAMS_SCHEMA_REGISTRY_HOST: schema-registry
#      STREAMS_SCHEMA_REGISTRY_PORT: 8081
#
#  rest-proxy:
#    image: confluentinc/cp-kafka-rest:7.9.0
#    depends_on:
#      - broker
#      - schema-registry
#    ports:
#      - 8082:8082
#    hostname: rest-proxy
#    container_name: rest-proxy
#    environment:
#      KAFKA_REST_HOST_NAME: rest-proxy
#      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker:29092'
#      KAFKA_REST_LISTENERS: "http://0.0.0.0:8082"
#      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
#
#  flink-sql-client:
#    image: cnfldemos/flink-sql-client-kafka:1.19.1-scala_2.12-java17
#    depends_on:
#      - flink-jobmanager
#    hostname: flink-sql-client
#    container_name: flink-sql-client
#    environment:
#      FLINK_JOBMANAGER_HOST: flink-jobmanager
#
#  flink-jobmanager:
#    image: cnfldemos/flink-kafka:1.19.1-scala_2.12-java17
#    hostname: flink-jobmanager
#    container_name: flink-jobmanager
#    ports:
#    - 9081:9081
#    command: jobmanager
#    environment:
#    - |
#      FLINK_PROPERTIES=
#      jobmanager.rpc.address: flink-jobmanager
#      rest.bind-port: 9081
#
#  flink-taskmanager:
#    image: cnfldemos/flink-kafka:1.19.1-scala_2.12-java17
#    hostname: flink-taskmanager
#    container_name: flink-taskmanager
#    depends_on:
#    - flink-jobmanager
#    command: taskmanager
#    scale: 1
#    environment:
#    - |
#      FLINK_PROPERTIES=
#      jobmanager.rpc.address: flink-jobmanager
#      taskmanager.numberOfTaskSlots: 10
networks:
  kafka-flink-net: